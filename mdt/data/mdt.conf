optimization_settings:
    # Please see the documentation of MOT.meta_optimizer for more information about the options
    general:
        # the optimizers to use. List at least one, can be more for use with extra_optim_runs > 0.
        # You can set the patience to null. Then the default patience for the optimizer is used.
        optimizers:
            -   name: 'Powell'
                patience: 2

        # The additional number of iterations, with either a random perturbation or a smoothing step in between.
        extra_optim_runs: 0

        # If we want to use smoothing or not. This is mutually exclusive with extra_optim_runs_use_perturbation.
        # This takes precedence over using perturbations.
        extra_optim_runs_apply_smoothing: False

        # If we want to use the parameter perturbation by the model or not.
        # This is mutually exclusive with extra_optim_runs_apply_smoothing.
        extra_optim_runs_use_perturbation: True

        # The smoothing routines to use during the extra runs, size is in voxels
        smoothing_routines:
            -   name: 'MedianFilter'
                size: [1, 1, 1]

        # The load balancer to use for the computations
        load_balancer:
            name: 'PreferGPU'
            run_in_batches: True
            single_batch_length: !!float 1.0e6

        # the indices of the devices we want to use for the computations.
        # This works in combination with the load balancers.
        # For the indices please run the script mdt-list-devices.
        # An empty list indicates that we want to use all devices.
        cl_devices: []

    # Optimizations settings for single models. This can overwrite any value from general_optimization_settings.
    # This uses regex expressions for matching the model_name. As keys for the items you can either provide
    # a string with a single regex, or you can provide a !!python/tuple [...] with multiple keys that is
    # partially matched if needed.
    #
    # Note 1) the optimization configuration hints in the cascades models takes precedence over these values.
    # Note 2) if you specify an optimizer in the fit_model function these settings are overwritten.
    model_specific: {}

# options for estimating the noise std before model fitting and or sampling
noise_std_estimating:
    general:
        # the optimization routine will use the given estimators in the given order
        estimators:
            -   AllUnweightedVolumes
            -   TwoUnweightedVolumes


# model protocol options for all model fitting and sampling
# same matching style as in the processing_strategies -> model_specific.
model_protocol_options:
    '^S0$':
        # the unweighted threshold in SI units of s/m^2
        unweighted_threshold: !!float 25e6
        use_weighted: False
        use_unweighted: True

    '^Tensor$':
        use_weighted: True
        use_unweighted: True

        # the unweighted threshold in SI units of s/m^2
        unweighted_threshold: !!float 25e6

        # Indicate to use b-values between [start, end], set b-values in s/m^2
        b_value:
            start: 0
            # for end we use 1.5e9 + eps
            end: !!float 1.6e9


# The strategies to for processing the models
processing_strategies:
    optimization:
        general:
            name: ProtocolDependent
            options:
                steps: [[0, 0], [100, 300000], [200, 200000]]

        # The processing strategies for specific models. This overrides the general processing strategy.
        # This uses regex expressions for matching the model_name. As keys for the items you can either provide
        # a string with a single regex, or you can provide a !!python/tuple [...] with multiple keys that is
        # partially matched if needed.
        #
        # Example for Noddi in a cascade:
        #
        # !!python/tuple ['^Noddi \(Cascade[|a-zA-Z0-9_]*\)$', '^Noddi']:
        #      name: SliceBySlice
        #
        model_specific:
            '^S0$':
                name: AllVoxelsAtOnce

            '^Noddi$':
                name: ProtocolDependent
                options:
                    steps: [[0, 0], [100, 150000], [200, 50000]]

            '^Charmed_r[1-2]$':
                name: ProtocolDependent
                options:
                    steps: [[0, 0], [100, 150000], [200, 50000]]

            '^Charmed$':
                name: ProtocolDependent
                options:
                    steps: [[0, 0], [100, 100000], [200, 25000]]

            '^BallStickStickStick$':
                name: ProtocolDependent
                options:
                    steps: [[0, 0], [100, 200000], [200, 100000]]

    sampling:
        general:
            name: VoxelRange
            options:
                nmr_voxels: 100000

        model_specific: {}


logging:
    info_dict:
        version: 1
        disable_existing_loggers: False
        formatters:
            simple:
                format: "[%(asctime)s] [%(levelname)s] [%(name)s] [%(funcName)s] - %(message)s"

        handlers:
            console:
                class: mdt.log_handlers.StdOutHandler
                level: INFO
                formatter: simple

            model_output_file:
                class: mdt.log_handlers.ModelOutputLogHandler
                level: DEBUG
                formatter: simple
                encoding: utf8

            dispatch_handler:
                class: mdt.log_handlers.LogDispatchHandler
                level: INFO
                formatter: simple

        loggers:
            mot:
                level: DEBUG
                handlers: [console, model_output_file]

            mdt:
                level: DEBUG
                handlers: [console, model_output_file]

        root:
            level: INFO
            handlers: [dispatch_handler]
